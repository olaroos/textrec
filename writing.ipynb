{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet as nnet\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import signal\n",
    "import time\n",
    "from math import sqrt\n",
    "from skimage import transform\n",
    "import skimage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions \n",
    "\n",
    "circle = lambda r: np.array([[1 if sqrt((i-r)**2 + (j-r)**2) <= r else 0 for j in range(0, 2*r+1)] for i in range(0, 2*r+1)])\n",
    "\n",
    "def absolute(x, y):\n",
    "    return(math.sqrt(x**2 + y**2))\n",
    "vect_absolute = np.vectorize(absolute)\n",
    "\n",
    "def power(input):\n",
    "    return input**2\n",
    "vect_power = np.vectorize(power)\n",
    "\n",
    "def get_rescaled(img, percent):\n",
    "    width, height = img.shape\n",
    "    resized = skimage.transform.resize(img, output_shape=[int(width * percent), \n",
    "                int(height * percent)], order=1, mode='constant', cval=0, clip=True, preserve_range=False)\n",
    "    return resized\n",
    "\n",
    "def calc_dist(histogram, x, y):\n",
    "    base = histogram[x][y]\n",
    "    rep_base = np.tile(base,(3, 1))\n",
    "    extended_base = np.ndarray((3, 3, 10))\n",
    "    extended_base[:] = rep_base\n",
    "    dist = (extended_base - histogram[x-1:x+2, y-1:y+2])\n",
    "    dist = np.power(dist, 2)\n",
    "    dist = np.sum(dist, axis=2)\n",
    "    dist = np.sqrt(dist)\n",
    "    dist = np.sum(np.sum(dist))\n",
    "    return dist\n",
    "\n",
    "def normalizeStd1Mean0(image):\n",
    "    image = image - np.mean(image)\n",
    "    return image/np.std(image)\n",
    "\n",
    "def histEq(image, number_bins=256):\n",
    "\n",
    "    # get image histogram\n",
    "    image_histogram, bins = np.histogram(image.flatten(), number_bins, normed=True)\n",
    "    cdf = image_histogram.cumsum() # cumulative distribution function\n",
    "    cdf = 255 * cdf / cdf[-1] # normalize\n",
    "\n",
    "    # use linear interpolation of cdf to find new pixel values\n",
    "    image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n",
    "\n",
    "    return image_equalized.reshape(image.shape), cdf\n",
    "\n",
    "def inverse(img):\n",
    "    return np.abs(img - 1)\n",
    "\n",
    "def threshold(img):\n",
    "    thresh = np.mean(img)\n",
    "    img[img > thresh] = 1\n",
    "    img[img <= thresh] = 0\n",
    "    return img\n",
    "\n",
    "# M1 \n",
    "# The variance of the greylevel histogram over a circular neighbourhood\n",
    "# of radius 3 (total area N = 29 pixels) at each pixel is used as a measure of how much local information there is:\n",
    "def calc_M1(img):\n",
    "    width, height = img.shape\n",
    "    bins = 10\n",
    "    histogram = np.ndarray((width, height, bins))\n",
    "    hist_variance = np.zeros((width, height))\n",
    "    radius = 3\n",
    "    kernel = circle(radius)\n",
    "    denominator = kernel.sum()\n",
    "    img_force_int = img.astype('float')\n",
    "    for x in range(radius, width-radius):\n",
    "        for y in range(radius, height-radius):\n",
    "            crop = img_force_int[x - radius:x + radius + 1, y - radius:y + radius + 1]\n",
    "            croped_crop = crop[kernel == 1]\n",
    "            hist, trash = np.histogram(croped_crop, bins)\n",
    "            histogram[x][y] = hist\n",
    "            var = np.nanvar(histogram[x][y])\n",
    "            hist_variance[x][y] = var\n",
    "        \n",
    "    M1 = hist_variance\n",
    "    return M1, histogram\n",
    "\n",
    "# M2\n",
    "# Text regions have a high density of edges. This density is measured in a circular neighbourhood of \n",
    "# radius 6 centred at each pixel by summing all edge magnitudes located with a Sobel filter:\n",
    "def calc_M2(img):\n",
    "    Gx_kernel = np.matrix([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    Gy_kernel = np.matrix([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "    Gx = signal.convolve2d(img, Gx_kernel, 'same')\n",
    "    Gy = signal.convolve2d(img, Gy_kernel, 'same')\n",
    "    G = vect_absolute(Gx, Gy)\n",
    "    G = G.astype(np.uint8)\n",
    "    # sum all edge magnitudes \n",
    "    kernel = circle(6)\n",
    "    M2 = signal.convolve2d(G, kernel, 'same')\n",
    "    \n",
    "    return M2\n",
    "\n",
    "# M3\n",
    "# the ratio of text to non-text intensity greylevels should not vary greatly as we pass over a text region.\n",
    "# hypothesise that there will be only a small change in local greylevel histograms across a text region.\n",
    "def calc_M3(histogramFromM1):\n",
    "    width, height, bins = histogramFromM1.shape\n",
    "    M3 = np.zeros((width, height))\n",
    "    for x in range(1, width-2):\n",
    "        for y in range(1, height-2):\n",
    "            dist = calc_dist(histogramFromM1, x, y)\n",
    "            M3[x][y] = dist\n",
    "\n",
    "    return M3\n",
    "\n",
    "# M4\n",
    "# In high resolution images one expects to find a high number of edges in a text region, and \n",
    "# the angles of the edges to be well distributed due to the presence of curves on many characters. \n",
    "# However, this will not be the case at low resolution, where individual characters merge and edges follow\n",
    "# the tops and bottoms of text lines.\n",
    "def calc_M4(img):\n",
    "    \n",
    "    width, height = img.shape\n",
    "    angle = 0\n",
    "    radius = 6\n",
    "    bins = 8\n",
    "    kernel = circle(radius)\n",
    "    \n",
    "    # calculate magnitude vector\n",
    "    Gx_kernel = np.matrix([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    Gy_kernel = np.matrix([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "    Gx = signal.convolve2d(img, Gx_kernel, 'same')\n",
    "    Gy = signal.convolve2d(img, Gy_kernel, 'same')\n",
    "    Gvector = np.ndarray([2, width, height])\n",
    "    Gvector[0, ...] = Gx\n",
    "    Gvector[1, ...] = Gy\n",
    "    magnitude = vect_absolute(Gx, Gy)\n",
    "    # calculate angles of magnitude\n",
    "    magnitude_angle = np.arctan2(Gx, Gy)\n",
    "\n",
    "    histograms = np.ndarray((width, height, 2, bins))\n",
    "    M4 = np.ndarray((width, height))\n",
    "    for x in range(radius, width - radius):\n",
    "        for y in range(radius, height - radius):\n",
    "            crop = magnitude_angle[(x - radius):(x + radius + 1), (y - radius):(y + radius + 1)]\n",
    "            cropped_with_kernel = crop[kernel == 1]\n",
    "            cropped_with_kernel = cropped_with_kernel.reshape(cropped_with_kernel.size, 1)\n",
    "            # mapp instances of 0 < x <= pi to 1 and pi < x <= 2pi to 0           \n",
    "            mapp = np.logical_and(0 < cropped_with_kernel, cropped_with_kernel <= math.pi)\n",
    "            # crop_1 is the angles from 0  to  pi\n",
    "            crop_1 = cropped_with_kernel[mapp == 1]\n",
    "            # crop_2 is the angles from pi to 2pi                 \n",
    "            crop_2 = cropped_with_kernel[mapp == 0]\n",
    "\n",
    "            # when the size of either part is zero we create a \"zero\" histogram,\n",
    "            # an array of zeros the size of the number of bins(in this case 8)\n",
    "            if (crop_1.size == 0):\n",
    "                histogram_1 = np.zeros(8)\n",
    "                histogram_2, trash = np.histogram(np.hstack(crop_2),bins)\n",
    "            elif (crop_2.size == 0):\n",
    "                histogram_1, trash = np.histogram(np.hstack(crop_1),bins)\n",
    "                histogram_2 = np.zeros(8)\n",
    "            else: \n",
    "                histogram_1, trash = np.histogram(np.hstack(crop_1),bins)            \n",
    "                histogram_2, trash = np.histogram(np.hstack(crop_2),bins)\n",
    "\n",
    "            diff = histogram_1 - np.flipud(histogram_2)\n",
    "            power = vect_power(diff)\n",
    "            result = math.sqrt(sum(power))\n",
    "            M4[x, y] = result\n",
    "            histograms[x, y, 0] = histogram_1\n",
    "            histograms[x, y, 1] = histogram_2\n",
    "        \n",
    "    return M4, histograms\n",
    "\n",
    "# M5\n",
    "# The first four measures respond in the same way to straight image features as to coarse or curved features. \n",
    "# This measure is employed to reject those areas of the image with tight distributions\n",
    "# of edges corresponding to straight ramps, canals or ridges in the image. \n",
    "# It examines how evenly spread the edge magnitudes are over all the directions:\n",
    "\n",
    "# use histograms calculated in M4\n",
    "def calc_M5(histogramFromM4):\n",
    "    bins = 8\n",
    "    width, height, trash, trash = histogramFromM4.shape\n",
    "    pi = math.pi\n",
    "    M5 = np.ndarray((width, height))\n",
    "    for x in range(0, width):\n",
    "        for y in range(0, height):\n",
    "            histogram_1 = histogramFromM4[x, y, 0]\n",
    "            histogram_2 = histogramFromM4[x, y, 1]\n",
    "            local_average = (sum(histogram_1) + sum(histogram_2))/(bins*2)\n",
    "            result = 0\n",
    "            for theta in range(0, 8):\n",
    "                result += (local_average - histogram_1[theta])**2\n",
    "                result += (local_average - histogram_2[theta])**2\n",
    "            M5[x, y] = result\n",
    "\n",
    "    return M5\n",
    "\n",
    "def sizeofimg(img):\n",
    "    W, H = img.shape\n",
    "    print \"W \" + str(W) + \" H \" + str(H)\n",
    "    \n",
    "def prepImg(fileName, scale):\n",
    "    img = cv2.imread(fileName, 0)\n",
    "    kernel = np.ones((5,5),np.float32)/25\n",
    "    dst = cv2.filter2D(img,-1,kernel)\n",
    "    img_rescaled = get_rescaled(dst, scale)    \n",
    "    return img_rescaled\n",
    "    \n",
    "def highlightText(img):\n",
    "    start = time.time()\n",
    "    \n",
    "    M1, histogramFromM1  = calc_M1(img)\n",
    "    print str(int(time.time() - start)) + \" sec\" + \"\\n\" + \"finished calculating M1\"\n",
    "    start = time.time()\n",
    "    \n",
    "    M2 = calc_M2(img)\n",
    "    print str(int(time.time() - start)) + \" sec\" + \"\\n\" + \"finished calculating M2\"\n",
    "    start = time.time()\n",
    "    \n",
    "    M3 = calc_M3(histogramFromM1)\n",
    "    print str(int(time.time() - start)) + \" sec\" + \"\\n\" + \"finished calculating M3\"\n",
    "    start = time.time()\n",
    "    \n",
    "    M4, histogramFromM4 = calc_M4(img)\n",
    "    print str(int(time.time() - start)) + \" sec\" + \"\\n\" + \"finished calculating M4\"\n",
    "    start = time.time()\n",
    "    \n",
    "    M5 = calc_M5(histogramFromM4)\n",
    "    print str(int(time.time() - start)) + \" sec\" + \"\\n\" + \"finished calculating M5\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # PART II takes less time, copy filters -- do not destroy variables.\n",
    "    M1cp = M1\n",
    "    M2cp = M2\n",
    "    M3cp = M3\n",
    "    M4cp = M4\n",
    "    M5cp = M5\n",
    "\n",
    "    # normalize each filter to zero mean and standard deviation 1\n",
    "    M1norm = normalizeStd1Mean0(M1cp)\n",
    "    M2norm = normalizeStd1Mean0(M2cp)\n",
    "    M3norm = normalizeStd1Mean0(M3cp)\n",
    "    M4norm = normalizeStd1Mean0(M4cp)\n",
    "    M5norm = normalizeStd1Mean0(M5cp)\n",
    "\n",
    "    # threshhold each image with cutoff mean\n",
    "    M1thresh = threshold(M1norm)\n",
    "    M2thresh = threshold(M2norm)\n",
    "    M3thresh = threshold(M3norm)\n",
    "    M4thresh = threshold(M4norm)\n",
    "    M5thresh = threshold(M5norm)\n",
    "\n",
    "    # combine filters\n",
    "    combine = inverse(M1thresh) + M2thresh + inverse(M3thresh) + inverse(M4thresh) + inverse(M5thresh)\n",
    "    combine[combine < 5] = 0\n",
    "    combine[combine == 5] = 1\n",
    "    \n",
    "#     # plot filters    \n",
    "#     plt.figure(num=None, figsize=(4, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "#     plt.imshow(M1, 'gray')\n",
    "#     plt.figure(num=None, figsize=(4, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "#     plt.imshow(M2, 'gray')\n",
    "#     plt.figure(num=None, figsize=(4, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "#     plt.imshow(M3, 'gray')\n",
    "#     plt.figure(num=None, figsize=(4, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "#     plt.imshow(M4, 'gray')\n",
    "#     plt.figure(num=None, figsize=(4, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "#     plt.imshow(M5, 'gray')\n",
    "    \n",
    "#     # plot result \n",
    "#     plt.figure(num=None, figsize=(4, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "#     plt.imshow(img, 'gray')\n",
    "#     plt.figure(num=None, figsize=(4, 4), dpi=200, facecolor='w', edgecolor='k')\n",
    "#     plt.imshow(combine, 'gray')\n",
    "\n",
    "    return combine    \n",
    "\n",
    "def createTrainingFile(Mfilter, img, filename):\n",
    "    assert(Mfilter.shape == img.shape)\n",
    "    radius = 3\n",
    "    \n",
    "    kernel = circle(radius)\n",
    "    width, height = img.shape\n",
    "    \n",
    "    theFile = open(filename, 'w')\n",
    "    for x in range(radius, width-radius):\n",
    "        for y in range(radius, height-radius):\n",
    "            crop = Mfilter[x - radius:x + radius + 1, y - radius:y + radius + 1]\n",
    "            croped_crop = crop[kernel == 1]\n",
    "            output = str(img[x][y]) + \" \"\n",
    "            for pixel in croped_crop:\n",
    "                output += str(pixel) + \" \"            \n",
    "            print>> theFile, output\n",
    "            \n",
    "    theFile.close() \n",
    "\n",
    "def readTrainingFile(filename):\n",
    "    \n",
    "    theFile = open(filename, 'r')\n",
    "    line = theFile.readline()\n",
    "    while line != None:\n",
    "        values = line.split()\n",
    "        target = float(values[0])\n",
    "        training = np.asarray(values[1:], dtype=float)\n",
    "        line = theFile.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = prepImg('./img/bok11.png', 0.2)    \n",
    "start = time.time()    \n",
    "M1, histogramFromM1  = calc_M1(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "createTrainingFile(M1, img, \"./trainingSet/training_01_M1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "0.043137254902\n",
      "[  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.    23.89  23.49  26.69  26.09   0.     0.    23.09\n",
      "  24.29  28.69   0.     0.    19.89  29.49  23.89  19.09]\n"
     ]
    }
   ],
   "source": [
    "readTrainingFile('./trainingSet/training_01_M1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
