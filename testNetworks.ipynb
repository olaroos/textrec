{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet as nnet\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTrainingFile(filename):\n",
    "    \n",
    "    theFile = open(filename, 'r')\n",
    "    line = theFile.readline()\n",
    "    while line != None:\n",
    "        values = line.split()\n",
    "        target = float(values[0])\n",
    "        training = np.asarray(values[1:], dtype=float)\n",
    "        line = theFile.readline()\n",
    "        \n",
    "def layer(x, w):\n",
    "    b = np.array([1], dtype=theano.config.floatX)\n",
    "    new_x = T.concatenate([x, b])\n",
    "    m = T.dot(w.T, new_x)\n",
    "    h = nnet.sigmoid(m)\n",
    "    return h\n",
    "\n",
    "def grad_desc(cost, theta):\n",
    "    alpha = 0.1 #learning rate\n",
    "    #     T.grad(function, wrt=theta)) \n",
    "    #     derive function with respect to theta\n",
    "    return theta - (alpha * T.grad(cost, wrt=theta))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.dvector()\n",
    "y = T.dscalar()\n",
    "\n",
    "theta1 = theano.shared(np.array(np.random.rand(30, 30), dtype=theano.config.floatX))\n",
    "theta2 = theano.shared(np.array(np.random.rand(30, 30), dtype=theano.config.floatX))\n",
    "theta3 = theano.shared(np.array(np.random.rand(31, 1), dtype=theano.config.floatX))\n",
    "\n",
    "# hidden layer\n",
    "hidl1 = layer(x, theta1)\n",
    "hidl2 = layer(hidl1, theta2)\n",
    "\n",
    "outl = T.sum(layer(hidl2, theta3))\n",
    "\n",
    "# cost expression\n",
    "fc = (outl - y)**2 \n",
    "\n",
    "cost = theano.function(inputs=[x, y], outputs=fc, updates=[\n",
    "        (theta1, grad_desc(fc, theta1)),\n",
    "        (theta2, grad_desc(fc, theta2)),\n",
    "        (theta3, grad_desc(fc, theta3))])\n",
    "\n",
    "run_forward = theano.function(inputs=[x], outputs=outl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        self.a = [np.ones((y, 1)) for y in sizes[1:]]\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        \"\"\"Change this, return a matrix with output values\"\"\"    \n",
    "        \n",
    "        \"\"\"WHAT TO DO HERE, I WANT TO LOOP OVER self.a,\n",
    "        A should be a reference that I can change.....\n",
    "        then wonderful things can happen\"\"\"\n",
    "        \n",
    "        for b, w, A in zip(self.biases, self.weights, self.a):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "            A = a\n",
    "            print A\n",
    "        return a\n",
    "\n",
    "    def outputError(self, z, y):\n",
    "        \"\"\"error = nabla_a C cdot sigmoid_prime(z)\n",
    "           error = \"\"\"\n",
    "        outputError = np.einsum('i,i->i', z - y, sigmoid_prime(z))\n",
    "        return outputError\n",
    "        \n",
    "    def backpropError(self, error1, w1, z0):\n",
    "        \"\"\"backpropagate error \n",
    "        newError = w^T * error cdot sigmoid_prime(z)\"\"\"\n",
    "        error0 = np.einsum('i,i->i', np.transpose(w1).dot(error1), sigmoid_prime(z0))\n",
    "        return newError\n",
    "    \n",
    "    def weightGrad(self, a0, error1):\n",
    "        \"\"\"need to repeat a0 and multiply with error or repeat error etc.\"\"\"\n",
    "        return np.dot(ao, error1)\n",
    "#         return np.einsum('i,i->i', a0, error1)\n",
    "    \n",
    "    def biasGrad(self, error):\n",
    "        \"\"\"only to remind me that this is the defined error\"\"\"\n",
    "        return error\n",
    "    \n",
    "    def trainNet(self, x, y):\n",
    "        out = feedforward(x)\n",
    "        outError = outputError(out)\n",
    "        \"\"\"now do I want to update the weights and biases before I backprop the error\n",
    "        I would want to calculate all the errors first and then loop through \n",
    "        them and update\"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86495135  0.8828662   0.65588752  0.79238165  0.67452493  0.87236252\n",
      "   0.73037898  0.54834318  0.24888009  0.70742711]\n",
      " [ 0.13489369  0.15504778  0.0443456   0.0850164   0.04803123  0.14265729\n",
      "   0.06186975  0.02870874  0.00800225  0.0555939 ]\n",
      " [ 0.74771786  0.77717802  0.4686562   0.63848187  0.48954208  0.75977576\n",
      "   0.5562572   0.35971949  0.13294642  0.52806054]\n",
      " [ 0.89805002  0.91202078  0.72386719  0.83997565  0.74028071  0.90384673\n",
      "   0.78839059  0.62543546  0.31305211  0.76881392]\n",
      " [ 0.37446892  0.41331609  0.15121418  0.26293121  0.16227362  0.38980801\n",
      "   0.20204138  0.10191261  0.03004002  0.18434092]\n",
      " [ 0.75751034  0.78615404  0.48177325  0.6505327   0.50269065  0.76924465\n",
      "   0.56919956  0.37192173  0.13912768  0.54114691]\n",
      " [ 0.51864367  0.55907971  0.24279654  0.39100558  0.25851406  0.534839\n",
      "   0.31305342  0.16960206  0.0527988   0.28915159]\n",
      " [ 0.86115008  0.87949895  0.64859242  0.78704066  0.66742459  0.86873821\n",
      "   0.72399854  0.54036589  0.24291627  0.70072608]\n",
      " [ 0.76603053  0.79394157  0.49350386  0.66113021  0.51442499  0.77747366\n",
      "   0.58067366  0.38295415  0.14484719  0.55278113]\n",
      " [ 0.50985508  0.55038939  0.23638678  0.38266046  0.25182736  0.5260759\n",
      "   0.30553731  0.1647043   0.05106665  0.28197378]]\n",
      "[[ 0.09281985  0.08760649  0.1472532   0.11209665  0.14232911  0.09069929\n",
      "   0.12788523  0.17712208  0.27807877  0.13377309]\n",
      " [ 0.08253167  0.07073528  0.23376073  0.13408558  0.2205671   0.07758974\n",
      "   0.17994896  0.30484634  0.45214061  0.19680007]\n",
      " [ 0.95019794  0.95365583  0.91838501  0.93757821  0.92073973  0.95161057\n",
      "   0.92825535  0.90596827  0.87787763  0.92507756]\n",
      " [ 0.96642835  0.97007947  0.92905896  0.95184386  0.93170837  0.96794324\n",
      "   0.94054908  0.91664886  0.90323357  0.93675425]\n",
      " [ 0.80266606  0.79658272  0.81588982  0.81470774  0.81651925  0.8003776\n",
      "   0.81719626  0.80969003  0.78131807  0.81716963]\n",
      " [ 0.16619814  0.15338841  0.23584245  0.20383597  0.23347773  0.16110115\n",
      "   0.22304351  0.24139457  0.21541469  0.22799627]\n",
      " [ 0.38981429  0.39234293  0.42458973  0.39148671  0.41857337  0.39068441\n",
      "   0.40303946  0.4655047   0.61250462  0.40892855]\n",
      " [ 0.99872902  0.99905303  0.98564383  0.99652433  0.98787814  0.99887154\n",
      "   0.99299483  0.96572616  0.80367534  0.9911527 ]\n",
      " [ 0.03808878  0.03244698  0.15371376  0.06719425  0.13926438  0.03568618\n",
      "   0.10101512  0.25279231  0.59727941  0.11581816]\n",
      " [ 0.63753333  0.61989767  0.70042888  0.67787202  0.69921974  0.63078838\n",
      "   0.69281725  0.70193719  0.68495973  0.69603757]]\n",
      "[[ 0.80437488  0.79695275  0.8551401   0.82731404  0.85199042  0.80141712\n",
      "   0.84152736  0.87094903  0.89686101  0.84603662]]\n",
      "[[ 0.80437488  0.79695275  0.8551401   0.82731404  0.85199042  0.80141712\n",
      "   0.84152736  0.87094903  0.89686101  0.84603662]]\n"
     ]
    }
   ],
   "source": [
    "net = Network([2, 10, 10, 1])\n",
    "\n",
    "\n",
    "out = net.feedforward([0, 1])\n",
    "\n",
    "\n",
    "print out \n",
    "# print net.a\n",
    "\n",
    "# w_next = np.ones((3, 5))\n",
    "# z_next = np.array([1, 2, 3])\n",
    "# z = np.array([1, 1, 1, 1, 1])\n",
    "# y = np.array([1, 1, 1])\n",
    "\n",
    "\n",
    "# error = net.outputError(z_next, y)\n",
    "# newError = net.backpropError(error, w_next, z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-b9feeac48033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print net.a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.61953908  0.59959084  0.55459293  0.56265256  0.72461614  0.7265567\n",
      "   0.55596404  0.5658212   0.67270275  0.63370964]]\n"
     ]
    }
   ],
   "source": [
    "output = net.feedforward([0, 1])\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "sizes = [4, 5, 5, 1]\n",
    "\n",
    "for x, y in zip(sizes[:-1], sizes[1:]):\n",
    "    print x\n",
    "    print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
