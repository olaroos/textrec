{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet as nnet\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import signal\n",
    "import time\n",
    "from math import sqrt\n",
    "from skimage import transform\n",
    "import skimage \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.602681965908778)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dscalar()\n",
    "fx = T.exp(T.sin(x**2))\n",
    "\n",
    "f = theano.function(inputs=[x], outputs=[fx])\n",
    "f(10)\n",
    "\n",
    "fp = T.grad(fx, wrt=x)\n",
    "fprime = theano.function([x], fp)\n",
    "fprime(15)\n",
    "\n",
    "x = T.dvector()\n",
    "y = T.dscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1 = theano.shared(np.array(np.random.rand(3,3), dtype=theano.config.floatX))\n",
    "theta2 = theano.shared(np.array(np.random.rand(4,1), dtype=theano.config.floatX))\n",
    "\n",
    "# theta1.eval()\n",
    "\n",
    "hidl = layer(x, theta1) #hidden layer\n",
    "outl = T.sum(layer(hidl, theta2)) #output layer\n",
    "fc = (outl - y)**2 #cost expression\n",
    "\n",
    "cost = theano.function(inputs=[x, y], outputs=fc, updates=[\n",
    "        (theta1, grad_desc(fc, theta1)),\n",
    "        (theta2, grad_desc(fc, theta2))])\n",
    "\n",
    "# updates allows us to update our shared variables according to an expression. \n",
    "# updates expects a list of 2-tuples:\n",
    "# updates=[(shared_variable, update_value), ...]\n",
    "run_forward = theano.function(inputs=[x], outputs=outl)                                         \n",
    "\n",
    "inputs = np.array([[0,1],[1,0],[1,1],[0,0]]).reshape(4,2) #training data X\n",
    "exp_y = np.array([1, 1, 0, 0]) #training data Y\n",
    "cur_cost = 0\n",
    "for i in range(10000):\n",
    "    for k in range(len(inputs)):\n",
    "        cut_cost = cost(inputs[k], exp_y[k])\n",
    "        if i % 5000 == 0: #only print the cost every 500 epochs/iterations (to save space)\n",
    "            print 'Cost: %s' % (cut_cost,)\n",
    "            \n",
    "            \n",
    "#Training done! Let's test it out\n",
    "print(run_forward([0,1]))\n",
    "print(run_forward([1,1]))\n",
    "print(run_forward([1,0]))\n",
    "print(run_forward([0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(x, w):\n",
    "    b = np.array([1], dtype=theano.config.floatX)\n",
    "    new_x = T.concatenate([x, b])\n",
    "    m = T.dot(w.T, new_x)\n",
    "    h = nnet.sigmoid(m)\n",
    "    return h\n",
    "\n",
    "def grad_desc(cost, theta):\n",
    "    alpha = 0.1 #learning rate\n",
    "    #     T.grad(function, wrt=theta)) \n",
    "    #     derive function with respect to theta\n",
    "    return theta - (alpha * T.grad(cost, wrt=theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# functions \n",
    "\n",
    "circle = lambda r: np.array([[1 if sqrt((i-r)**2 + (j-r)**2) <= r else 0 for j in range(0, 2*r+1)] for i in range(0, 2*r+1)])\n",
    "\n",
    "def absolute(x, y):\n",
    "    return(math.sqrt(x**2 + y**2))\n",
    "vect_absolute = np.vectorize(absolute)\n",
    "\n",
    "def power(input):\n",
    "    return input**2\n",
    "vect_power = np.vectorize(power)\n",
    "\n",
    "def normalizeNPA(img):\n",
    "    w, h = img.shape\n",
    "    denominator = np.ones((w, h)) * np.amax(img)\n",
    "    return img/denominator\n",
    "\n",
    "def get_rescaled(img, percent):\n",
    "    width, height = img.shape\n",
    "    resized = skimage.transform.resize(img, output_shape=[int(width * percent), \n",
    "                int(height * percent)], order=1, mode='constant', cval=0, clip=True, preserve_range=False)\n",
    "    return resized\n",
    "\n",
    "def crop_img(img, radius):\n",
    "    width, height = img.shape\n",
    "    return img[radius:width - radius, radius:height - radius]\n",
    "\n",
    "def cutgreylevels(img, begin_p, end_p):\n",
    "    maxval = img.max()\n",
    "    diff_mapp = np.logical_and(maxval * begin_p < img, img < maxval * end_p)\n",
    "    cut = diff_mapp * img\n",
    "    output = np.divide(cut - cut.min(), cut.max())\n",
    "    return output\n",
    "\n",
    "def calc_dist(histogram, x, y):\n",
    "    base = histogram[x][y]\n",
    "    rep_base = np.tile(base,(3, 1))\n",
    "    extended_base = np.ndarray((3, 3, 10))\n",
    "    extended_base[:] = rep_base\n",
    "    dist = (extended_base - histogram[x-1:x+2, y-1:y+2])\n",
    "    dist = np.power(dist, 2)\n",
    "    dist = np.sum(dist, axis=2)\n",
    "    dist = np.sqrt(dist)\n",
    "    dist = np.sum(np.sum(dist))\n",
    "    return dist\n",
    "\n",
    "def get_scale(magnitude_angle, angle):\n",
    "    # returns the ammount the magnitude should be scaled in \n",
    "    # reference to given angle only count positive values     \n",
    "    output = abs((1 - np.absolute(np.divide(magnitude_angle - angle, math.pi/2))))\n",
    "    return output\n",
    "\n",
    "def get_mapp(magnitude_angle, angle):\n",
    "    # -pi <= angle <= pi \n",
    "    # determines if the magnitude_angle is pointing in the same direction as the \n",
    "    mapp_angles = np.logical_and(magnitude_angle <= math.pi/2 + angle, magnitude_angle >= -math.pi/2 + angle)\n",
    "    return mapp_angles\n",
    "\n",
    "def normalizeStd1Mean0(image):\n",
    "    image = image - np.mean(image)\n",
    "    return image/np.std(image)\n",
    "\n",
    "def histEq(image, number_bins=256):\n",
    "\n",
    "    # get image histogram\n",
    "    image_histogram, bins = np.histogram(image.flatten(), number_bins, normed=True)\n",
    "    cdf = image_histogram.cumsum() # cumulative distribution function\n",
    "    cdf = 255 * cdf / cdf[-1] # normalize\n",
    "\n",
    "    # use linear interpolation of cdf to find new pixel values\n",
    "    image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n",
    "\n",
    "    return image_equalized.reshape(image.shape), cdf\n",
    "\n",
    "def inverse(img):\n",
    "    return np.abs(img - 1)\n",
    "\n",
    "def threshold(img):\n",
    "    thresh = np.mean(img)\n",
    "    img[img > thresh] = 1\n",
    "    img[img <= thresh] = 0\n",
    "    return img\n",
    "\n",
    "# M1 \n",
    "# The variance of the greylevel histogram over a circular neighbourhood\n",
    "# of radius 3 (total area N = 29 pixels) at each pixel is used as a measure of how much local information there is:\n",
    "\n",
    "def calc_M1(img):\n",
    "    width, height = img.shape\n",
    "    bins = 10\n",
    "    histogram = np.ndarray((width, height, bins))\n",
    "    hist_variance = np.zeros((width, height))\n",
    "    radius = 3\n",
    "    kernel = circle(radius)\n",
    "    denominator = kernel.sum()\n",
    "    img_force_int = img.astype('float')\n",
    "    for x in range(radius, width-radius):\n",
    "        for y in range(radius, height-radius):\n",
    "            crop = img_force_int[x - radius:x + radius + 1, y - radius:y + radius + 1]\n",
    "            croped_crop = crop[kernel == 1]\n",
    "            hist, trash = np.histogram(np.hstack(croped_crop),bins)\n",
    "            histogram[x][y] = hist\n",
    "            var = np.nanvar(histogram[x][y])\n",
    "            hist_variance[x][y] = var\n",
    "    \n",
    "#     histogram_croped = histogram[radius:width - radius, radius:height - radius]\n",
    "#     hist_variance_croped = hist_variance[radius:width - radius, radius:height - radius]    \n",
    "    M1 = hist_variance\n",
    "    return M1, histogram\n",
    "\n",
    "# M2\n",
    "# Text regions have a high density of edges. This density is measured in a circular neighbourhood of \n",
    "# radius 6 centred at each pixel by summing all edge magnitudes located with a Sobel filter:\n",
    "\n",
    "def calc_M2(img):\n",
    "    Gx_kernel = np.matrix([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    Gy_kernel = np.matrix([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "    Gx = signal.convolve2d(img, Gx_kernel, 'same')\n",
    "    Gy = signal.convolve2d(img, Gy_kernel, 'same')\n",
    "    G = vect_absolute(Gx, Gy)\n",
    "    G = G.astype(np.uint8)\n",
    "    # sum all edge magnitudes \n",
    "    kernel = circle(6)\n",
    "    M2 = signal.convolve2d(G, kernel, 'same')\n",
    "    \n",
    "    return M2\n",
    "\n",
    "# M3\n",
    "# the ratio of text to non-text intensity greylevels should not vary greatly as we pass over a text region.\n",
    "# hypothesise that there will be only a small change in local greylevel histograms across a text region.\n",
    "\n",
    "def calc_M3(histogramFromM1):\n",
    "    width, height, bins = histogramFromM1.shape\n",
    "    M3 = np.zeros((width, height))\n",
    "    for x in range(1, width-2):\n",
    "        for y in range(1, height-2):\n",
    "            dist = calc_dist(histogramFromM1, x, y)\n",
    "            M3[x][y] = dist\n",
    "\n",
    "    return M3\n",
    "\n",
    "# M4\n",
    "# In high resolution images one expects to find a high number of edges in a text region, and \n",
    "# the angles of the edges to be well distributed due to the presence of curves on many characters. \n",
    "# However, this will not be the case at low resolution, where individual characters merge and edges follow\n",
    "# the tops and bottoms of text lines.\n",
    "\n",
    "# Different take on the filter, only use angle not magnitude. \n",
    "\n",
    "def calc_M4(img):\n",
    "    \n",
    "    width, height = img.shape\n",
    "    angle = 0\n",
    "    radius = 6\n",
    "    bins = 8\n",
    "    kernel = circle(radius)\n",
    "    \n",
    "    # calculate magnitude vector\n",
    "    Gx_kernel = np.matrix([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    Gy_kernel = np.matrix([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "    Gx = signal.convolve2d(img, Gx_kernel, 'same')\n",
    "    Gy = signal.convolve2d(img, Gy_kernel, 'same')\n",
    "    Gvector = np.ndarray([2, width, height])\n",
    "    Gvector[0, ...] = Gx\n",
    "    Gvector[1, ...] = Gy\n",
    "    magnitude = vect_absolute(Gx, Gy)\n",
    "    # calculate angles of magnitude\n",
    "    magnitude_angle = np.arctan2(Gx, Gy)\n",
    "\n",
    "    histograms = np.ndarray((width, height, 2, bins))\n",
    "    M4 = np.ndarray((width, height))\n",
    "    # print(crop.size)\n",
    "    for x in range(radius, width - radius):\n",
    "        for y in range(radius, height - radius):\n",
    "            crop = magnitude_angle[(x - radius):(x + radius + 1), (y - radius):(y + radius + 1)]\n",
    "            cropped_with_kernel = crop[kernel == 1]\n",
    "            cropped_with_kernel = cropped_with_kernel.reshape(cropped_with_kernel.size, 1)\n",
    "            # mapp instances of 0 < x <= pi to 1 and pi < x <= 2pi to 0           \n",
    "            mapp = np.logical_and(0 < cropped_with_kernel, cropped_with_kernel <= math.pi)\n",
    "            # crop_1 is the angles from 0  to  pi\n",
    "            # crop_2 is the angles from pi to 2pi     \n",
    "            crop_1 = cropped_with_kernel[mapp == 1]\n",
    "            crop_2 = cropped_with_kernel[mapp == 0]\n",
    "\n",
    "            # when the size of either part is zero we create a \"zero\" histogram,\n",
    "            # an array of zeros the size of the number of bins(in this case 8)\n",
    "            if (crop_1.size == 0):\n",
    "                histogram_1 = np.zeros(8)\n",
    "                histogram_2, trash = np.histogram(np.hstack(crop_2),bins)\n",
    "            elif (crop_2.size == 0):\n",
    "                histogram_1, trash = np.histogram(np.hstack(crop_1),bins)\n",
    "                histogram_2 = np.zeros(8)\n",
    "            else: \n",
    "                histogram_1, trash = np.histogram(np.hstack(crop_1),bins)            \n",
    "                histogram_2, trash = np.histogram(np.hstack(crop_2),bins)\n",
    "\n",
    "            diff = histogram_1 - np.flipud(histogram_2)\n",
    "            power = vect_power(diff)\n",
    "            result = math.sqrt(sum(power))\n",
    "            M4[x, y] = result\n",
    "            histograms[x, y, 0] = histogram_1\n",
    "            histograms[x, y, 1] = histogram_2\n",
    "    \n",
    "#     histograms_croped = histograms[radius:width - radius, radius:height - radius]\n",
    "    \n",
    "    return M4, histograms\n",
    "\n",
    "# M5\n",
    "# The first four measures respond in the same way to straight image features as to coarse or curved features. \n",
    "# This measure is employed to reject those areas of the image with tight distributions\n",
    "# of edges corresponding to straight ramps, canals or ridges in the image. \n",
    "# It examines how evenly spread the edge magnitudes are over all the directions:\n",
    "\n",
    "# use histograms calculated in M4\n",
    "def calc_M5(histogramFromM4):\n",
    "    bins = 8\n",
    "    width, height, trash, trash = histogramFromM4.shape\n",
    "    pi = math.pi\n",
    "    M5 = np.ndarray((width, height))\n",
    "    for x in range(0, width):\n",
    "        for y in range(0, height):\n",
    "            histogram_1 = histogramFromM4[x, y, 0]\n",
    "            histogram_2 = histogramFromM4[x, y, 1]\n",
    "            local_average = (sum(histogram_1) + sum(histogram_2))/(bins*2)\n",
    "            result = 0\n",
    "            for theta in range(0, 8):\n",
    "                # use absolute value\n",
    "    #             result += abs(local_average - histogram_1[theta])\n",
    "    #             result += abs(local_average - histogram_2[theta])\n",
    "                # use power of\n",
    "                result += (local_average - histogram_1[theta])**2\n",
    "                result += (local_average - histogram_2[theta])**2\n",
    "            M5[x, y] = result\n",
    "\n",
    "    return M5\n",
    "\n",
    "\n",
    "def sizeofimg(img):\n",
    "    W, H = img.shape\n",
    "    print \"W \" + str(W) + \" H \" + str(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# start = time.time()\n",
    "# img = cv2.imread('./img/bok11.png', 0)\n",
    "# kernel = np.ones((5,5),np.float32)/25\n",
    "# dst = cv2.filter2D(img,-1,kernel)\n",
    "# img_rescaled = get_rescaled(dst, 0.2)\n",
    "\n",
    "# M1, histogramFromM1  = calc_M1(img_rescaled)\n",
    "# print str(int(time.time() - start)) + \" sec\" + \"\\n\" + \"finished calculating M1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# M1network\n",
    "x = T.dvector()\n",
    "y = T.dscalar()\n",
    "\n",
    "theta1 = theano.shared(np.array(np.random.rand(30, 30), dtype=theano.config.floatX))\n",
    "theta2 = theano.shared(np.array(np.random.rand(31, 1), dtype=theano.config.floatX))\n",
    "\n",
    "# hidden layer\n",
    "hidl = layer(x, theta1)\n",
    "outl = T.sum(layer(hidl, theta2))\n",
    "\n",
    "# cost expression\n",
    "fc = (outl - y)**2 \n",
    "\n",
    "cost = theano.function(inputs=[x, y], outputs=fc, updates=[\n",
    "        (theta1, grad_desc(fc, theta1)),\n",
    "        (theta2, grad_desc(fc, theta2))])\n",
    "\n",
    "run_forward = theano.function(inputs=[x], outputs=outl)\n",
    "\n",
    "# create training set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00687268  0.54626472  0.13093505]\n",
      " [ 0.98454958  0.69208057  0.77864069]\n",
      " [ 0.6477946   0.71290119  0.5988397 ]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(4.623604303236651e-15)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what = np.random.rand(3, 3)\n",
    "print what\n",
    "\n",
    "\n",
    "width, height = M1.shape\n",
    "width = 10\n",
    "height = 10\n",
    "radius = 3\n",
    "kernel = circle(3)\n",
    "trainingset = np.zeros([1, 29])\n",
    "# print trainingset[0].reshape(1,3)\n",
    "# np.hstack(trainingset, np.array())\n",
    "print trainingset\n",
    "target = np.zeros([1])\n",
    "# print trainingset[0]\n",
    "\n",
    "\n",
    "\n",
    "# np.hstack((trainingset, np.ndarray((2,1))))\n",
    "# np.append(trainingset, np.ndarray((2,1)))\n",
    "# np.append(trainingset, np.ndarray((2,1)))\n",
    "# print trainingset\n",
    "\n",
    "M1cp = M1.astype('float')\n",
    "col = 10\n",
    "row = 10\n",
    "crop = M1cp[col - radius:col + radius + 1, row - radius:row + radius + 1]\n",
    "croped_crop = crop[kernel == 1]\n",
    "\n",
    "# cost(trainingset[0], target[0])\n",
    "cost(croped_crop, target[0])\n",
    "\n",
    "for col in range(radius, width-radius):\n",
    "    for row in range(radius, height-radius):\n",
    "        crop = M1[col - radius:col + radius + 1, row - radius:row + radius + 1]\n",
    "        croped_crop = crop[kernel == 1]\n",
    "        np.hstack(trainingset, croped_crop)\n",
    "        np.hstack(target, M1[col, row])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-129-03ca57ff877f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-129-03ca57ff877f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    x+,y+\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def hardCodedKernel():\n",
    "               x+,y+\n",
    "                3,0\n",
    "        1,1 2,1 3,1 4,1 5,1 \n",
    "        1,2 2,2 3,2 4,2 5,2\n",
    "    0,3 1,3 2,3 3,3 4,3 5,3 6,3\n",
    "        1,4 2,4 3,4 4,4 5,4 \n",
    "        1,5 2,5 3,5 4,5 5,5\n",
    "                3,6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
